{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "414b2477-efe5-4abc-bb88-ec923dd08d00",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-50eb2e113907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkerastuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHyperParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     raise ImportError(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m   _current_module.__path__ = (\n\u001b[1;32m    383\u001b[0m       [_module_util.get_parent_dir(keras)] + _current_module.__path__)\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrappers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandarallel\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from keras.activations import relu\n",
    "from keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, ReLU\n",
    "from kerastuner.tuners import RandomSearch, Sklearn\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1d1332-cbba-4a15-9d81-078f61d41449",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./EDA Notebook - Encoded.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9512f6f-2e10-407c-ba8d-0052a8cb865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822a890d-306e-47a9-97e4-f25a207396d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting DataFrame by our index before setting it as such\n",
    "# df.sort_values(by=[\"host_since\"], inplace=True, ascending=True)   # host_since is the closest thing to a date or date_time column we have\n",
    "# df.set_index(\"host_since\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b3b77-caa2-45e5-ab35-9336ee084223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7794eb-cac5-4110-94c7-afe3a7d70880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce3b36-3b14-4d7c-a4ff-a51c3cf72d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into target and feature matrix\n",
    "target = 'price'\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e889e100-f4d9-46eb-8f8c-7bd30acac6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "assert len(X) == len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d16efc-da3d-4ecf-ad1d-3b797886eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ddc44-43f7-4489-a706-44196da2a315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715d3d9-6451-4b10-a22e-688b50ea77b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standardizating data\n",
    "X_scaled = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92784cf7-3b4f-4ac7-9267-cf5e0d311d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6307411-d6fe-4ec9-8c9d-c01b1a40a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.38, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa14118-71d6-4cb6-b2f0-cfc80bae255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Checks\n",
    "len(X_train) == len(y_train)\n",
    "len(X_val) == len(y_val)\n",
    "len(X_test) == len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8440e653-24b7-4f02-afaf-02b77f6b6960",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Rows for Training Set: \", len(X_train))\n",
    "print(\"Number of Rows for Validation Set: \", len(X_val))\n",
    "print(\"Number of Rows for Testing Set: \", len(X_test))\n",
    "# The validation set is smaller than the testing set. This is why I have the second train_test_split in\n",
    "# an odd arrangement, had to make sure val was smaller than test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a223ce59-d73e-4c25-adee-733753829e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Baseline\n",
    "y_pred = [y_train.mean()] * len(y_train)\n",
    "\n",
    "baseline_mae = mean_absolute_error(y_train, y_pred)\n",
    "print('Baseline MAE:', baseline_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa596d-51da-4013-9d04-8af3563b2b1c",
   "metadata": {},
   "source": [
    "## Building Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f898e2-488a-41fd-8835-9f93e7ee505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dim of image row vectors and save to imput_dim\n",
    "imput_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e716f0-a4cc-495d-b411-ba53648e9661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_regression_model(hp):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns a complied keras model ready for keras-tuner gridsearch algorithms \n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # 1st hidden layer\n",
    "    model.add(Dense(input_dim=imput_dim,\n",
    "                    units=hp.get('units'),\n",
    "                    activation=hp.get(\"activation\")))\n",
    "    \n",
    "    # 2nd hidden layer \n",
    "    model.add(Dense(units=hp.get('units'),\n",
    "                    activation=hp.get(\"activation\")))\n",
    "    \n",
    "    # 2nd hidden layer \n",
    "    model.add(Dense(units=hp.get('units'),\n",
    "                    activation=hp.get(\"activation\")))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(hp.get('learning_rate')),\n",
    "        loss='mse',\n",
    "        metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc9550f-8d2a-4d41-bd01-4d30fb244687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build out our hyperparameter dictionary \n",
    "hp = HyperParameters()\n",
    "hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "hp.Choice('learning_rate',values=[1e-1, 1e-2, 1e-3])\n",
    "hp.Choice('activation',values=[\"linear\", \"relu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbcd290-e755-4479-9322-1586615d0ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique_hparam_combos = len(range(32,512+32, 32)) * 3 *2\n",
    "n_param_combos_to_sample = n_unique_hparam_combos * .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77690ef-c695-4081-a0c0-7f8f31444d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tuner = RandomSearch(\n",
    "            build_regression_model,\n",
    "            objective='val_mae',\n",
    "            max_trials=n_param_combos_to_sample, # number of times to sample the parameter set and build a model \n",
    "            seed=1234,\n",
    "            hyperparameters=hp, # pass in our hyperparameter dictionary\n",
    "            directory='./keras-tuner-trial',\n",
    "            project_name='random_search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7667eded-e499-4877-9248-0595c66eb937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take note of Total elapsed time in print out\n",
    "random_tuner.search(X_train,\n",
    "                    y_train,\n",
    "                    epochs=3,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd32a49-5680-41da-a859-2d430d35dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the best score and hyperparamter (should be at the top since scores are ranked)\n",
    "random_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3892e6bd-08c0-4517-9c58-8e6e8beef469",
   "metadata": {},
   "source": [
    "# Trial summary\n",
    "\n",
    "\n",
    "## Hyperparameters:\n",
    "\n",
    "*units:* **416**\n",
    "\n",
    "*learning_rate:* **0.001**\n",
    "\n",
    "*activation:* **relu**\n",
    "\n",
    "---\n",
    "*Score:* **91.08583068847656**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4db6f3-ca24-4229-8cc8-3a0fc13057fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plugging in best params\n",
    "\n",
    "# Instantiating our model's class architecture\n",
    "model = Sequential()\n",
    "    \n",
    "# hidden layer\n",
    "model.add(Dense(10,\n",
    "                input_dim=imput_dim,  # Input layer\n",
    "                activation='relu'))\n",
    "\n",
    "# 2nd hidden layer\n",
    "model.add(Dense(480, activation='relu'))\n",
    "    \n",
    "# output layer\n",
    "model.add(Dense(1,\n",
    "                activation='relu'))\n",
    "\n",
    "# Assigning learning rate to RMSprop optimizer\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "# compiling our model architecture with loss function & corresponding metric\n",
    "model.compile(optimizer=opt,\n",
    "              loss='mse',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f16f30-bd59-42f1-bdc4-fa6519e97c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d833df-1480-4c88-bbde-0339ea9e181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TensorBoard if you're running this on Colab\n",
    "\n",
    "# %load_ext tensorboard\n",
    "\n",
    "# import os\n",
    "# import datetime\n",
    "\n",
    "# logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d663fee3-3269-4924-9590-f650c9a6ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readying our EarlyStop callback\n",
    "# stop_callback = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c2ef47-852d-41c4-8bb7-744a21397daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=32,\n",
    "          epochs=20,\n",
    "          validation_data=(X_val, y_val))\n",
    "\n",
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165fd644-9260-4e50-b63a-c65ddcffd27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517292f1-e946-4682-b258-24dacc0f9215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating model's predictive power\n",
    "predictions = model.predict(X_test, batch_size=32)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11041af6-5ba1-4ef5-8721-cc7b61c5929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual prices\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cd4805-ef0c-458f-bbb5-3959cf741780",
   "metadata": {},
   "source": [
    "Not a good model. Going to try a GridSearchCV & BayesianOptimization next. This will have to suffice considering its 4:27 AM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2951641e-52a8-4330-b7ad-7aa53d146a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m69"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
